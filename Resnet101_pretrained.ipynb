{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('../input/covid19-image-dataset/Covid19-dataset'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport torch\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\nbatch_size = 20\nnum_workers = 0\n\ndata_dir = '../input/covid19-image-dataset/Covid19-dataset'\ntrain_dir = os.path.join(data_dir, 'train')\n\ntest_dir = os.path.join(data_dir, 'test')\ndata_transforms = {'train': transforms.Compose([transforms.RandomResizedCrop(224),\n                                     transforms.RandomHorizontalFlip(),\n                                     transforms.ToTensor(),\n                                   transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                              std=[0.229, 0.224, 0.225]) ]),\n                   'val': transforms.Compose([transforms.Resize(256),\n                                     transforms.CenterCrop(224),\n                                     transforms.ToTensor(),\n                                     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                              std=[0.229, 0.224, 0.225])]),\n                   'test': transforms.Compose([transforms.Resize(size=(224,224)),\n                                     transforms.ToTensor(), \n                                     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                              std=[0.229, 0.224, 0.225])])\n                  }\n\ntrain_data = datasets.ImageFolder(train_dir, transform=data_transforms['train'])\ntest_data = datasets.ImageFolder(test_dir, transform=data_transforms['test'])\n\ntrain_loader = torch.utils.data.DataLoader(train_data,\n                                           batch_size=batch_size, \n                                           num_workers=num_workers,\n                                           shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_data,\n                                           batch_size=batch_size, \n                                           num_workers=num_workers,\n                                           shuffle=False)\nloaders_scratch = {\n    'train': train_loader,\n    'test': test_loader\n}","execution_count":2,"outputs":[{"output_type":"stream","text":"../input/covid19-image-dataset/Covid19-dataset/test/Normal/0121.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Normal/0109.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Normal/0117.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Normal/0102.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Normal/0107.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Normal/0106.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Normal/0111.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Normal/0114.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Normal/0118.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Normal/0122.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Normal/0119.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Normal/0103.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Normal/0112.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Normal/0105.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Normal/0120.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Normal/0116.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Normal/0115.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Normal/0108.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Normal/0101.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Normal/0110.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Viral Pneumonia/0113.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Viral Pneumonia/0104.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Viral Pneumonia/0109.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Viral Pneumonia/0117.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Viral Pneumonia/0102.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Viral Pneumonia/0107.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Viral Pneumonia/0106.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Viral Pneumonia/0111.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Viral Pneumonia/0114.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Viral Pneumonia/0118.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Viral Pneumonia/0119.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Viral Pneumonia/0103.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Viral Pneumonia/0112.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Viral Pneumonia/0105.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Viral Pneumonia/0120.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Viral Pneumonia/0116.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Viral Pneumonia/0115.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Viral Pneumonia/0108.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Viral Pneumonia/0101.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Viral Pneumonia/0110.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Covid/COVID-00003b.jpg\n../input/covid19-image-dataset/Covid19-dataset/test/Covid/COVID-00033.jpg\n../input/covid19-image-dataset/Covid19-dataset/test/Covid/0113.jpg\n../input/covid19-image-dataset/Covid19-dataset/test/Covid/0102.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Covid/0100.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Covid/0106.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Covid/COVID-00037.jpg\n../input/covid19-image-dataset/Covid19-dataset/test/Covid/0120.jpg\n../input/covid19-image-dataset/Covid19-dataset/test/Covid/0105.png\n../input/covid19-image-dataset/Covid19-dataset/test/Covid/098.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Covid/auntminnie-2020_01_31_20_24_2322_2020_01_31_x-ray_coronavirus_US.jpg\n../input/covid19-image-dataset/Covid19-dataset/test/Covid/auntminnie-c-2020_01_28_23_51_6665_2020_01_28_Vietnam_coronavirus.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Covid/0118.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Covid/radiopaedia-2019-novel-coronavirus-infected-pneumonia.jpg\n../input/covid19-image-dataset/Covid19-dataset/test/Covid/auntminnie-d-2020_01_28_23_51_6665_2020_01_28_Vietnam_coronavirus.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Covid/0119.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Covid/0112.jpg\n../input/covid19-image-dataset/Covid19-dataset/test/Covid/COVID-00022.jpg\n../input/covid19-image-dataset/Covid19-dataset/test/Covid/0111.jpg\n../input/covid19-image-dataset/Covid19-dataset/test/Covid/094.png\n../input/covid19-image-dataset/Covid19-dataset/test/Covid/096.png\n../input/covid19-image-dataset/Covid19-dataset/test/Covid/0115.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Covid/0108.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Covid/COVID-00012.jpg\n../input/covid19-image-dataset/Covid19-dataset/test/Covid/auntminnie-a-2020_01_28_23_51_6665_2020_01_28_Vietnam_coronavirus.jpeg\n../input/covid19-image-dataset/Covid19-dataset/test/Covid/auntminnie-b-2020_01_28_23_51_6665_2020_01_28_Vietnam_coronavirus.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/01.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/025.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/024.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/059.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/052.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/074.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/055.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/056.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/021.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/066.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/088.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/067.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/068.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/081.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/075.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/07.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/086.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/092.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/095.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/017.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/019.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/083.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/022.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/061.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/080.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/082.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/023.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/073.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/064.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/04.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/011.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/018.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/087.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/08.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/096.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/057.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/050.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/071.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/05.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/010.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/065.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/016.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/093.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/070.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/077.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/053.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/097.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/079.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/09.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/058.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/069.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/062.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/013.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/03.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/014.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/085.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/060.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/02.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/020.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/084.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/072.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/015.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/094.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/063.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/076.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/06.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/091.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/012.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/054.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Normal/051.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/01.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/025.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/042.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/024.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/027.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/052.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/074.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/038.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/055.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/056.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/021.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/036.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/066.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/067.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/068.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/081.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/075.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/041.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/07.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/048.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/095.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/045.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/019.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/043.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/083.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/022.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/061.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/033.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/037.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/082.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/047.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/023.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/073.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/064.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/04.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/011.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/018.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/08.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/096.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/057.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/071.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/032.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/05.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/034.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/010.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/065.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/016.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/078.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/077.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/053.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/046.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/09.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/058.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/044.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/062.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/013.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/03.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/02.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/020.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/084.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/072.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/094.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/063.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/076.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/06.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/031.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/012.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/054.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/051.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Viral Pneumonia/035.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/074.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/061.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/01.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00027.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/090.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00003b.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00025.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00033.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/091.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/071.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/025.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/042.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/024.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/027.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/059.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/076.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00032.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/052.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/033.png\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00001.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00002.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/082.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/068.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00005.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/055.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/021.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/010.png\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00019.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/073.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00023.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/088.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00037.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/081.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/019.png\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/041.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/039.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00028.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/048.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00015a.png\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/045.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/067.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00007.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/086.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/043.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/083.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/022.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00015b.png\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00016.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/092.png\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/047.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00004.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00010.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/040.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/080.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00030.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00018.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/08.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00013a.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00011.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/064.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/057.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/050.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/032.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/015.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00014.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00013b.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/020.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00031.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/065.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00020.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00034.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/078.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00038.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/053.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/046.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00009.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00008.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00022.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/079.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00006.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00017.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/089.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/058.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/044.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/04.png\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/062.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00036.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00003a.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/07.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/03.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/09.png\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/085.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/049.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/060.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/02.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/084.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/072.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00012.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00021.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/06.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00029.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00035.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/031.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/069.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00026.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/026.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/012.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/056.jpg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/054.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/051.jpeg\n../input/covid19-image-dataset/Covid19-dataset/train/Covid/COVID-00024.jpg\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torchvision.models as models\nuse_cuda = torch.cuda.is_available()","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## TODO: Specify data loaders\nloaders_transfer=loaders_scratch.copy()","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torchvision.models as models\nimport torch.nn as nn\n\n## TODO: Specify model architecture \n\n# Select a pre-trained VGG19 CNN\nmodel_transfer=models.resnet101(pretrained=True)\n\n","execution_count":37,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-37-8ab71817c26c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Select a pre-trained VGG19 CNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel_transfer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet152\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mresnet152\u001b[0;34m(pretrained, progress, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \"\"\"\n\u001b[1;32m    288\u001b[0m     return _resnet('resnet152', Bottleneck, [3, 8, 36, 3], pretrained, progress,\n\u001b[0;32m--> 289\u001b[0;31m                    **kwargs)\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_resnet\u001b[0;34m(arch, block, layers, pretrained, progress, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_resnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         state_dict = load_state_dict_from_url(model_urls[arch],\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, block, layers, num_classes, zero_init_residual, groups, width_per_group, replace_stride_with_dilation, norm_layer)\u001b[0m\n\u001b[1;32m    152\u001b[0m                                        dilate=replace_stride_with_dilation[0])\n\u001b[1;32m    153\u001b[0m         self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n\u001b[0;32m--> 154\u001b[0;31m                                        dilate=replace_stride_with_dilation[1])\n\u001b[0m\u001b[1;32m    155\u001b[0m         self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n\u001b[1;32m    156\u001b[0m                                        dilate=replace_stride_with_dilation[2])\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_make_layer\u001b[0;34m(self, block, planes, blocks, stride, dilate)\u001b[0m\n\u001b[1;32m    195\u001b[0m             layers.append(block(self.inplanes, planes, groups=self.groups,\n\u001b[1;32m    196\u001b[0m                                 \u001b[0mbase_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m                                 norm_layer=norm_layer))\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inplanes, planes, stride, downsample, groups, base_width, dilation, norm_layer)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv3x3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv1x1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplanes\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpansion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplanes\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpansion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mconv1x1\u001b[0;34m(in_planes, out_planes, stride)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconv1x1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_planes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_planes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;34m\"\"\"1x1 convolution\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_planes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_planes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode)\u001b[0m\n\u001b[1;32m    340\u001b[0m         super(Conv2d, self).__init__(\n\u001b[1;32m    341\u001b[0m             \u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             False, _pair(0), groups, bias, padding_mode)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, bias, padding_mode)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bias'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mreset_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkaiming_uniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mfan_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_fan_in_and_fan_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/init.py\u001b[0m in \u001b[0;36mkaiming_uniform_\u001b[0;34m(tensor, a, mode, nonlinearity)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstd\u001b[0m  \u001b[0;31m# Calculate uniform bounds from standard deviation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_transfer\n\nif use_cuda:\n    model_transfer = model_transfer.cuda()","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.optim as optim\nimport torch.nn as nn\ncriterion_transfer = nn.CrossEntropyLoss()\noptimizer_transfer = optim.SGD(model_transfer.parameters(), lr=0.005)","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n    \"\"\"returns trained model\"\"\"\n    # initialize tracker for minimum validation loss\n    valid_loss_min = np.Inf \n    \n    for epoch in range(1, n_epochs+1):\n        # initialize variables to monitor training and validation loss\n        train_loss = 0.0\n        valid_loss = 0.0\n        \n        ###################\n        # train the model #\n        ###################\n        model.train()\n        for batch_idx, (data, target) in enumerate(loaders['train']):\n            # move to GPU\n            if use_cuda:\n                data, target = data.cuda(), target.cuda()\n            ## find the loss and update the model parameters accordingly\n            \n            #clearing the gradients\n            optimizer.zero_grad()\n            \n            #predicted output\n            output=model(data)\n            \n            \n            loss = criterion(output, target)\n            # backward propogation\n            loss.backward()\n            \n            optimizer.step()\n            # update training loss\n            \n            \n            ## record the average training loss, using something like\n            ## train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n            \n            \n            if batch_idx % 100 == 0:\n                print('Epoch %d, Batch %d loss: %.6f' %\n                  (epoch, batch_idx + 1, train_loss))\n        ######################    \n        # validate the model #\n        ######################\n        model.eval()\n        for batch_idx, (data, target) in enumerate(loaders['test']):\n            # move to GPU\n            if use_cuda:\n                data, target = data.cuda(), target.cuda()\n            ## update the average validation loss\n\n            # forward pass\n            output = model(data)\n            # loss\n            loss = criterion(output, target)\n            # update validation loss\n            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n        \n          \n        \n        # print training/validation statistics \n        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n            epoch, \n            train_loss,\n            valid_loss\n            ))\n        \n        ## TODO: save the model if validation loss has decreased\n      \n    if valid_loss <= valid_loss_min:\n            print('Validation loss decreased ({:.6f} --> {:.6f}).    Saving model...'.format(valid_loss_min, valid_loss))\n            torch.save(model.state_dict(), save_path)\n            valid_loss_min = valid_loss\n        \n    # return trained model\n    return model","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_transfer = train(5, loaders_transfer, model_transfer, optimizer_transfer, criterion_transfer, use_cuda, 'model_transfer.pt')\n\n# load the model that got the best validation accuracy (uncomment the line below)\nmodel_transfer.load_state_dict(torch.load('model_transfer.pt'))","execution_count":31,"outputs":[{"output_type":"stream","text":"Epoch 1, Batch 1 loss: 9.217237\nEpoch: 1 \tTraining Loss: 4.400350 \tValidation Loss: 2.709507\nEpoch 2, Batch 1 loss: 0.976606\nEpoch: 2 \tTraining Loss: 0.625608 \tValidation Loss: 1.261217\nEpoch 3, Batch 1 loss: 0.404602\nEpoch: 3 \tTraining Loss: 0.400272 \tValidation Loss: 0.562432\nEpoch 4, Batch 1 loss: 0.258950\nEpoch: 4 \tTraining Loss: 0.387061 \tValidation Loss: 1.182591\nEpoch 5, Batch 1 loss: 0.589598\nEpoch: 5 \tTraining Loss: 0.306122 \tValidation Loss: 0.441539\nValidation loss decreased (inf --> 0.441539).    Saving model...\n","name":"stdout"},{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\ndef test(loaders, model, criterion, use_cuda):\n\n    # monitor test loss and accuracy\n    test_loss = 0.\n    correct = 0.\n    total = 0.\n\n    model.eval()\n    for batch_idx, (data, target) in enumerate(loaders['test']):\n        # move to GPU\n        if use_cuda:\n            data, target = data.cuda(), target.cuda()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the loss\n        loss = criterion(output, target)\n        # update average test loss \n        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n        # convert output probabilities to predicted class\n        pred = output.data.max(1, keepdim=True)[1]\n        # compare predictions to true label\n        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n        total += data.size(0)\n            \n    print('Test Loss: {:.6f}\\n'.format(test_loss))\n\n    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n        100. * correct / total, correct, total))","execution_count":32,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test(loaders_transfer, model_transfer, criterion_transfer, use_cuda)","execution_count":33,"outputs":[{"output_type":"stream","text":"Test Loss: 0.441539\n\n\nTest Accuracy: 87% (58/66)\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}